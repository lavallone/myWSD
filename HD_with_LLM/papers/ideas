#############################
######## U-WSD  LLMs ########
#############################

https://static.googleusercontent.com/media/research.google.com/it//pubs/archive/45729.pdf (LSTM and label propagation)
- it appears lack of sufficient labeled training data for large vocabularies is the central problem --> that's why we published the previous paper!
- Previous investigations (Navigli, 2006; Navigli et al., 2007) using the ODE have shown that coarse-grained word senses induced by the ODE inventory address problems with WordNetâ€™s fine-grained inventory, and that the inventory is useful for word sense disambiguation.

https://www.jair.org/index.php/jair/article/view/11259/26454 (survey on sense embeddings)
- Word embeddings have demonstrated their effectiveness in storing valuablesyntactic  and  semantic  information.
- the  effectiveness of  word  embeddings  is  generally  hampered  by  an  important  limitationwhich we will refer to asmeaning conflation deficiency: the inability to discriminate among different  meanings  of  a  word.
- frequent words tend to have more senses, according to the Principle of Economical Versatility of Words (ZIPF law).
- The main idea behind word VSM is that words that share similar context should be close inthe vector space.
- Learning low-dimensional vectors from text corpora can alternatively be achieved by ex-ploiting  neural  networks.   These  models  are  commonly  known  asword  embeddingsandhave been shown to provide valuable prior knowledge thanks to their generalization power(Goldberg,  2016). 
- Learning low-dimensional vectors from text corpora can alternatively be achieved by ex-ploiting  neural  networks.   These  models  are  commonly  known  asword  embeddingsandhave been shown to provide valuable prior knowledge thanks to their generalization power(Goldberg,  2016). !!!
- In order to alleviate this deficiency, a new direction of research has emerged over the pastyears, which tries to directly model individual meanings of words.
- A solution to addressing the meaning conflation deficiency of word embeddings is to repre-sent individual meanings of words, i.e., word senses, as independent representations.
- Inaddition, the fact that WSD relies on knowledge resources poses additional challenges suchas the creation of such resources and the construction of sense-annotated corpora.
- Textual definitionsare used as main signals for initializing sense embeddings by several approaches.
- intrinsic vs extrinsic evaluations: Extrinsic  evaluation  procedures  aim  at  assessing  the  quality  of  meaning  representationswithin a downstream task. In addition to intrinsic evaluation procedures, extrinsic evalua-tion is necessary to understand the effectiveness of different sense representation techniquesin real-world applications.
- one of the main goals of researchin  meaning  representations  is  to  enable  effective  integration  of  these  knowledge  carriersinto downstream applications.  Unlike word representations (and more specifically embed-dings), sense representations are still in their infancy in this regard.

